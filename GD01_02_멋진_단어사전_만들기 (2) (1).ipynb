{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLR2Ssvs2Zmt"
   },
   "source": [
    "# 데이터 다운로드 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JOZwrcHMhnm5"
   },
   "outputs": [],
   "source": [
    "#프로젝트에 사용될 라이브러리 import\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CF3Y4f8Rh7Qm"
   },
   "source": [
    " 학습환경을 구성하고 데이터를 다운받아보자.\n",
    "\n",
    "wget https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
    "\n",
    "mkdir -p ~/aiffel/sp_tokenizer/data\n",
    "\n",
    "mv korean-english-park.train.tar.gz ~/aiffel/sp_tokenizer/data\n",
    "\n",
    "cd ~/aiffel/sp_tokenizer/data\n",
    "\n",
    "tar -xzvf korean-english-park.train.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dvd0IT3oiJqX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
      ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
      ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
     ]
    }
   ],
   "source": [
    "#디렉토리 불러와서 변수(raw)로 지정.\n",
    "path_to_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko'\n",
    "  # 사용자의 홈 디렉토리 경로를 가져온 후, 해당 경로에 '\\aiffel~'을 추가하여 파일 경로를 만듦.\n",
    "with open(path_to_file, \"r\") as f:  #'path_to_file' 경로로 파일을 열고, 이 파일을 'f'라는 변수로 열게 됨.\n",
    "    raw = f.read().splitlines()  #파일 내용을 읽어온 후, 'read()'함수로 파일 내용 전체를 문자열로 읽어옴.\n",
    "                                 #'splitlines()'함수를 사용하여 문자열을 줄 단위로 분리하여 리스트로 저장.\n",
    "                                 #이렇게 하면 파일의 각 줄이 리스트이 원소로 들어감.\n",
    "\n",
    "print(\"Data Size:\", len(raw))  #읽어온 데이터의 크기를 출력. len(raw)는 'raw'리스트의 길이를 나타냄.\n",
    "\n",
    "print(\"Example:\")\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)  #'raw'리스트에서 처음 100개의 원소를 선택한 후, 20의 간격으로 원소를 순회.\n",
    "                                               #0번째 문장, 20번째 문장, 40번째 문장, 60번째 문장, 80번째 문장이 선택된 원소들.\n",
    "                                               #선택된 원소 'sen'을 출력. '>>'와 함께 선택된 원소의 내용이 출력됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ulf5FGJx1BhV"
   },
   "source": [
    "data size: 94123\n",
    "\n",
    "0, 20, 40, 60, 80번째 문장이 Example로 출력됐다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ICXeXv_ZiaGX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 377\n",
      "문장의 평균 길이: 60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#문장 길이 확인.\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in raw:  #'raw'리스트에 있는 각 문장('sen')에 대해 반복문을 실행\n",
    "    length = len(sen)  #현재 문장'sen'의 길이를 구해서 'length'변수에 할당\n",
    "    if min_len > length: min_len = length  #현재 문장의 길이가 ' min_len'변수에 저장된 최소 길이보다 작다면, 'min_len'변수에 현재 길이를 저장.\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length  #현재 문장의 길이를 'sum_len'변수에 더함. 'sum_len'변수는 전체 길이의 합을 나타내며, 문장 길이의 총합을 계산\n",
    "    #'raw'리스트에 잇는 모든 문장을 반복하면서 각 문장의 길이를 계산하고, 최소 길이와 최대 길이를 업데이트하며 전체 길이의 합을 계산.\n",
    "\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(raw))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)  #길이가 'max_len'이고 0으로 초기화된 Numpy 배열\n",
    "                                                  #sentence_length 배열의 dtype = 정수\n",
    "\n",
    "for sen in raw:  #'raw'리스트에 있는 각 문장('sen')에 대해 반복문을 실행\n",
    "    sentence_length[len(sen)-1] += 1  #'len(sen)-1': 현재 문장의 길이에서 1을 뺀 값 = 문장 길이를 배열 인덱스에 맞게 변환\n",
    "                                      #길이가 1인 문장은 배열의 첫 번째 요소에 저장. 길이가 2인 문장은 두 번째 요소에 저장.\n",
    "                                      #계산된 인덱스 위치에 해당하는 'sentence_length'배열의 값을 1 증가. 이를 통해 해당 길이의 문장이 등장한 빈도를 저장.\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ2glI7IwBBU"
   },
   "source": [
    "문장의 최단 길이:1\n",
    "\n",
    "문장의 최장 길이:377\n",
    "\n",
    "문장의 평균 길이:60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v1kAQ4BjwHDd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’\n"
     ]
    }
   ],
   "source": [
    "#길이가 1인 문장은 무엇인가?\n",
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0  #변수'count'를 초기화\n",
    "\n",
    "    for sen in raw:\n",
    "        if len(sen) == length:  #현재 문장'sen'의 길이가 지정한 길이'length'와 일치하는지 검사\n",
    "            print(sen)\n",
    "            count += 1  #길이가 일치하는 문장을 찾았으면 'count'변수를 1 증가시킴.\n",
    "            if count > 100: return  #변수'count'가 100을 초과하면 함수를 종료.\n",
    "                                    #이는 문장이 너무 많아서 출력을 100개로 제한하고자 할 때 사용.\n",
    "\n",
    "check_sentence_with_length(raw, 1)  #길이가 1인 문장을 찾아서 출력."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ud_iypGw8Fy"
   },
   "source": [
    ">>>> '\n",
    "\n",
    "길이가 1인 문장은 노이즈 데이터였다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ohaObGocxDQb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Index: 11\n",
      "Outlier Index: 19\n",
      "Outlier Index: 21\n"
     ]
    }
   ],
   "source": [
    "#문장의 수가 1500을 초과하는 문장의 길이를 추출\n",
    "for idx, _sum in enumerate(sentence_length):  #배열의 각 요소와 해당 요소의 인덱스를 반복하면서 'idx'와 'sum' 변수가 값을 할당.\n",
    "                                              #'enumerate()'함수를 사용하여 인덱스와 요소를 한 번에 가져옴.\n",
    "                                              #'idx'변수는 현재 문장의 길이를 의미.\n",
    "    if _sum > 1500:\n",
    "        print(\"Outlier Index:\", idx+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLHY_zg_yc8E"
   },
   "source": [
    "문장의 수가 1500을 초과하는 문장 길이는 각각  11, 19, 21이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "N7DUPClKycd_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라고 조던이 말했다.\n",
      "- 모르고 있습니다.\n",
      "- 네, 보이는군요.\n",
      "디즈니사만이 아니다.\n",
      "큰 파티는 아니지요.\n",
      "의자는 비어 있었다.\n",
      "이 일은 계속됩니다.\n",
      "나는 크게 실망했다.\n",
      "그 이유는 간단하다.\n",
      "이력서와 자기 소개서\n",
      "시대가 변하고 있다.\n",
      "는 돌발질문을 했다.\n",
      "9. 몇 분간의 명상\n",
      "하와이, 빅 아일랜드\n",
      "키스를 잘 하는 방법\n",
      "키스를 잘 하는 방법\n",
      "스피어스가 뚱뚱한가?\n",
      "산 위를 나는 느낌.\n",
      "세 시간쯤 걸었을까?\n",
      "(아직 읽고있습니까?\n",
      "처음에는 장난이었다.\n",
      "우리는 운이 좋았다.\n",
      "아기가 숨을 멈출 때\n",
      "건물 전체 무너져내려\n",
      "그녀의 아름다운 눈.\n",
      "대답은 다음과 같다.\n",
      "\"사과할 것이 없다.\n",
      "폭탄테러가 공포 유발\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "조금은 새침한 샬롯？\n",
      "조금은 새침한 샬롯？\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n"
     ]
    }
   ],
   "source": [
    "#길이가 11인 문장들은 어떤 것들이 있을까?\n",
    "check_sentence_with_length(raw, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwXu_Eg2ytFz"
   },
   "source": [
    "중복에 대한 처리도 제대로 되지 않아보인다.\n",
    "\n",
    "중복 제거 -> Python의 기본 자료형인 'set'을 활용\n",
    "\n",
    "    'set': 집합을 정의하는 자료형.\n",
    "    중복을 허용하지 않아 변환 과정에서 자동으로 중복된 요소를 제거\n",
    "    다만, list의 순서가 뒤죽박죽될 수 있으니, 쌍을 이루는 데이터는 주의!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eW3pWt6vyskY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 77591\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 377\n",
      "문장의 평균 길이: 64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#중복 제거후 다시 길이 분포를 확인.\n",
    "\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(raw))  #'raw'리스트를 'set'으로 변환하여 중복을 제거하고 다시 'list()'로 감싸서 리스트로 변환.\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sentence_length[len(sen)-1] += 1  #문장의 길이를 배열 인덱스에 맞게 변환하는 역할\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDpYsPG_zw4o"
   },
   "source": [
    "data size:77591\n",
    "\n",
    "문장의 최단 길이:1\n",
    "\n",
    "문장의 최장 길이:377\n",
    "\n",
    "문장의 평균 길이:64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oe63Ik1s1Mpo"
   },
   "source": [
    "'모든 데이터를 다 사용할 것이냐?'에 대한 선택.\n",
    "\n",
    "미니 배치를 만들 것을 생각하면 모든 데이터를 다 사용하는 것은 연산 측면에서 비효율적.\n",
    "\n",
    "    미니 배치 특성상, 각 데이터의 크기가 모두 동일해야하기 때문에 가장 긴 데이터를 기준으로 padding 처리를 해야함.\n",
    "\n",
    "여기서는 길이 150 이상의 데이터를 제거하고 사용.\n",
    "\n",
    "또한 너무 짧은 데이터는 오히려 노이즈로 작용할 수 있으니, 길이가 10 미만이 데이터도 제거.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rhT3NBtY15XF"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 150\n",
    "min_len = 10\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택하여 'filtered_corpus'리스트에 저장.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려봄.\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwZx30sz2fF-"
   },
   "source": [
    "# 공백 기반 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YUyJ9ziM2iVQ"
   },
   "outputs": [],
   "source": [
    "#입력된 문장들을 토큰화하고 숫자로 변환하여 텐서로 변환하는 함수를 정의하는 작업.\n",
    "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "                       #'tokenize'함수: 토큰화된 문장들을 입력으로 받아서 처리하고, 토큰화된 텐서와 토크나이저를 반환\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "     #입력 텍스트를 토큰화하고, 토큰들을 숫자로 매핑하는 역할.\n",
    "     #'filters='''는 특정 문자들을 필터링하지 않겠다는 의미 = 모든 문자를 토큰화\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "     #corpus에 있는 문장들을 기반으로 단어 사전을 생성. 이렇게 생성된 단어 사전은 각 단어를 고유한 정수로 매핑하는 역할\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "     #문장들을 숫자 시퀀스로 변환. 각 단어가 생성된 단어사전에서 매핑된 정수로 대체됨.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "     #변환된 숫자 시퀀스를 패딩하여 모든 문장의 길이를 동일하게 함.\n",
    "     #'padding='post''는 패딩을 시퀀스의 뒷부분에 적용하라는 의미.\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RcVCom4g44s5"
   },
   "outputs": [],
   "source": [
    "#공백 기반 토큰화하여 저장.\n",
    "split_corpus = []  #'split_corpus'는 이후에 반환된 단어들의 리스트를 저장할 목적으로 사용될 빈 리스트.\n",
    "\n",
    "for kor in filtered_corpus:  #'filtered_corpus'리스트에 있는 각 문장('kor')에 대해 반복문을 실행\n",
    "    split_corpus.append(kor.split())  #현재 문장'kor'를 공백을 기준으로 분할하고 단어들의 리스트로 변환하고, 그 결과를 'split_corpus'리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZgBbSa2556Of"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Vocab Size: 237435\n"
     ]
    }
   ],
   "source": [
    "#'split_corpus'를 공백 기반 토큰화하여 숫자 시퀀스로 변환하고, 그 결과로 생성된 토크나이저의 단어 사전 크기를 출력.\n",
    "\n",
    "split_tensor, split_tokenizer = tokenize(split_corpus)\n",
    "  #'tokenize'함수를 사용해 'split_corpus'에 있는 문장들을 토큰화하여 텐서'split_tensor'와 토크나이저'split_tokenizer'를 얻음.\n",
    "  #'tokenize'함수에 패딩까지 포함되어 있음.\n",
    "print(\"Split Vocab Size:\", len(split_tokenizer.index_word))\n",
    "  #생성된 'split_tokenizer'의 단어 사전의 크기를 출력.\n",
    "  #'index_word'속성: 정수로 매핑된 단어들의 딕셔너리."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QKAIZYo8XIJ"
   },
   "source": [
    "공백 기반 토크나이저의 단어 사전 크기: 237435\n",
    "\n",
    "해당 토크나이저가 처리한 데이터의 고유한 단어의 개수가 237435개라는 의미이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WggRfGKK8oHW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 이\n",
      "1 : 밝혔다.\n",
      "2 : 있다.\n",
      "3 : 말했다.\n",
      "4 : 수\n",
      "5 : 있는\n",
      "6 : 그는\n",
      "7 : 대한\n",
      "8 : 위해\n",
      "9 : 전했다.\n",
      "10 : 지난\n",
      "11 : 이번\n"
     ]
    }
   ],
   "source": [
    "#'split_tokenizer' 단어 사전의 각 단어와 그에 해당하는 인덱스를 출력.\n",
    "for idx, word in enumerate(split_tokenizer.word_index):  #for 반복문을 통해 단어 사전을 열거\n",
    "   #'enumerate'함수를 사용하여 각 단어와 해당하는 인덱스를 반복문 변수 'idx'와 'word'로 받아옴\n",
    "\n",
    "    print(idx, \":\", word)\n",
    "\n",
    "    if idx > 10: break #인덱스 0부터 11까지 출력한 후 반복문을 종료."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUYvwN2T9vLt"
   },
   "source": [
    "유사한 의미를 지닌 '밝혔다.'와 '밝히다', '밝다'는 전혀 다른 단어로 분류되고 있음.\n",
    "\n",
    "즉, 공백 기반 토큰화는 불필요하게 큰 단어 사전을 가지게 되어 연산량을 증가시킴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goLV3_Y5-B4U"
   },
   "source": [
    "#형태소 기반 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-mecab-ko in /opt/conda/lib/python3.9/site-packages (1.3.3)\n",
      "Requirement already satisfied: python-mecab-ko-dic in /opt/conda/lib/python3.9/site-packages (from python-mecab-ko) (2.1.1.post2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-mecab-ko\n",
    "from mecab import MeCab\n",
    "mecab = MeCab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aY-65XSe-FxR"
   },
   "outputs": [],
   "source": [
    "#'mecab'라이브러리를 사용하여 한국어 문장을 형태소로 분리하고, 그 결과를 'mecab_corpus'리스트에 저장.\n",
    "\n",
    "def mecab_split(sentence):\n",
    "    return mecab.morphs(sentence)  #'mecab_morphs()'함수: 한국어 문장을 형태소 단위로 분리하는 기능\n",
    "\n",
    "mecab_corpus = []  #분리된 형태소들을 저장할 목적의 빈 리스트\n",
    "\n",
    "for kor in filtered_corpus:  #'filtered_corpus'리스트에 있는 각 문장('kor')에 대해 반복문을 실행\n",
    "    mecab_corpus.append(mecab_split(kor))\n",
    "     #현재 문장('kor')를'mecab_split'함수에 넣어 형태소로 분리한 결과를 'mecab_corpus'리스트에 추가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NF2OEEQY_Fv0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeCab Vocab Size: 52279\n"
     ]
    }
   ],
   "source": [
    "#형태소 기반 토큰화된 'mecab_corpus'를 숫자 시퀀스로 변환하고, 그 결과로 생성된 토크나이저의 단어 사전 크기를 출력.\n",
    "mecab_tensor, mecab_tokenizer = tokenize(mecab_corpus)\n",
    "\n",
    "print(\"MeCab Vocab Size:\", len(mecab_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXJ-5f-W_am1"
   },
   "source": [
    "형태소 기반 토크나이저의 단어 사전 크기: 52779\n",
    "\n",
    "공백 기반 토크나이저의 단어 사전 크기(237435)에 비해 단어 수가 현저히 줄어듦.\n",
    "\n",
    "이는 곧 연산량 감소로이어져 더 빠른 학습을 가능케 하고, 모델이 튜닝해야 하는 parameter 수가 줄어 들어 학습도 잘됨.\n",
    "\n",
    "적어도 한국어를 처리할 때는 공백 기반 토큰화를 절 대 지 양!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LRw20QlCRXz"
   },
   "source": [
    "# 디코딩: Tensor -> 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HPDpeGomCvEb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' 종군 위안부 ' 는 일본 이 2 차 세계 대전 당시 성 노예 로 강제 징집 했 던 수천 명 의 여성 을 이르 는 말 이 다 .\n"
     ]
    }
   ],
   "source": [
    "#'tokenizer.sequences_to_texts()'함수를 사용하여 mecab_tensor[100]을 디코딩\n",
    "\n",
    "texts = mecab_tokenizer.sequences_to_texts([mecab_tensor[100]])\n",
    "  #'mecab_tensor' 중 101번째 데이터를 선택하여 텍스트로 변환.\n",
    "  #'sequences_to_texts()'함수는 리스트를 입력으로 받으므로 리스트로 감싸서 입력\n",
    "print(texts[0])  #texts리스트의 첫 번째 원소를 출력. 어차피 texts리스트는 101번째 데이터 하나만 선택했기때문에 원소가 1개이긴함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BtkqpNXqEBtL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'종군위안부'는일본이2차세계대전당시성노예로강제징집했던수천명의여성을이르는말이다.\n"
     ]
    }
   ],
   "source": [
    "#'tokenizer.index_word'를 사용하여 mecab_tensor[100]을 디코딩\n",
    "\n",
    "sentence = ''\n",
    "\n",
    "for w in mecab_tensor[100]:  #101번째 데이터에 있는 각 숫자를 반복. 'w'변수: 현재 숫자를 나타냄.\n",
    "    if w == 0: continue  #'w'가 0인 경우는 패딩으로 나타내므로 무시하고 넘어감.\n",
    "    sentence += mecab_tokenizer.index_word[w] + ''\n",
    "      #현재 숫자'w'에 해당하는 단어를 'mecab_tokenizer.index_word'를 사용하여 단어로 변환하고, sentence에 추가.\\\n",
    "      #이때 단어 사이에 공백을 추가하여 문장을 구성.\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvDxBor0619d"
   },
   "source": [
    "# 프로젝트 : 멋진 단어사전 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egyGSDRx7ADS"
   },
   "source": [
    "##STEP1. SentencePiece 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oDe4NJI768UR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pnibED77Dwk"
   },
   "source": [
    "##STEP2. SentencePiece 모델 학습\n",
    "\n",
    "spm(SentencePiece)는 오픈 소스의 자연어 처리 라이브러리로서, 서브워드 토큰화를 수행하는 도구이다.\n",
    "\n",
    "서브워드 토큰화는 단어를 더 작은 단위로 분할하여 처리하는 방법으로, 공백 단위나 형태소 단위로 토큰화하지 않고도 언어의 복잡성을 다룰 수 있다.\n",
    "\n",
    "    토크나이저를 학습?훈련?\n",
    "    A) 주어진 텍스트 데이터에서 어떤 패턴을 학습하여 토큰화할 것인지 결정하고 학습된 토크나이저 모델을 파일로 저장한다. 저장된 토크나이저 모델을 사용하여 실제 텍스트 데이터를 토큰 단위로 분리하여 처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ExB00FKm7J9v"
   },
   "outputs": [],
   "source": [
    "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pF4iTVRr7Nnw"
   },
   "source": [
    "tf.keras.preprocessing.text.Tokenizer에 corpus를 입력하고 tokenizer.fit_on_texts(corpus)을 하면 토크나이저 내부적으로 단어사전과 토크나이저 기능을 corpus에 맞춤형으로 자동 생성해줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DWJmvgvl7OXw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path_to_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko'\n",
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "cleaned_corpus = list(set(raw))\n",
    "\n",
    "max_len = 150\n",
    "min_len = 10\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택하여 'filtered_corpus'리스트에 저장.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nqawIvMs7SUu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp --model_prefix=korean_spm --vocab_size=8000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
      "  input_format: \n",
      "  model_prefix: korean_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 76908 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=4996369\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1317\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 76908 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 174340 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 76908\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 237965\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 237965 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=92555 obj=14.853 num_tokens=523272 num_tokens/piece=5.65363\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=82083 obj=13.516 num_tokens=525776 num_tokens/piece=6.40542\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=61555 obj=13.5533 num_tokens=546907 num_tokens/piece=8.88485\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=61506 obj=13.5101 num_tokens=547350 num_tokens/piece=8.89913\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=46126 obj=13.6926 num_tokens=575369 num_tokens/piece=12.4739\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=46126 obj=13.6493 num_tokens=575466 num_tokens/piece=12.476\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=34594 obj=13.8894 num_tokens=606014 num_tokens/piece=17.5179\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=34594 obj=13.8387 num_tokens=606012 num_tokens/piece=17.5178\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=25945 obj=14.1301 num_tokens=637532 num_tokens/piece=24.5724\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25945 obj=14.0747 num_tokens=637568 num_tokens/piece=24.5738\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=19458 obj=14.4091 num_tokens=670960 num_tokens/piece=34.4825\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=19458 obj=14.3468 num_tokens=670999 num_tokens/piece=34.4845\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14593 obj=14.7196 num_tokens=705636 num_tokens/piece=48.3544\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14593 obj=14.648 num_tokens=705645 num_tokens/piece=48.355\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10944 obj=15.0875 num_tokens=741620 num_tokens/piece=67.765\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=10944 obj=15.007 num_tokens=741624 num_tokens/piece=67.7654\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=15.3757 num_tokens=769363 num_tokens/piece=87.4276\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=15.307 num_tokens=769367 num_tokens/piece=87.4281\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: korean_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korean_spm.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 376816 Aug 16 08:10 korean_spm.model\r\n",
      "-rw-r--r-- 1 root root 146213 Aug 16 08:10 korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전에 나왔던 정제했던 corpus를 활용해서 진행해야 합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(  #sentencepiece를 사용하여 토크나이저를 훈련\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)\n",
    ")  #'input':입력 파일 지정, 'model_prefix': 모델의 이름 접두사 설정, 'vocab_size': 어휘 사전 크기 지정\n",
    "#위 Train에서  --model_type = unigram이 디폴트 적용되어 있습니다. --model_type = bpe로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*  #훈련된 sentencepiece 모델 파일과 관련 파일을 확인하기 위한 명령어. 훈련된 모든 파일이 출력됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWCXR1687W_V"
   },
   "source": [
    "위 코드를 실행하면 정상적으로 sentencepiece 모델 학습이 완료된 후 korean_spm.model파일과 korean_spm.vocab vocabulary 파일이 생성되었음을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zmnXb4sU7Xu0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1243, 11, 302, 7, 3608, 11, 287, 38, 3]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezaTQAB_7c3P"
   },
   "source": [
    "##STEP3. Tokenizer 함수 작성\n",
    "\n",
    "훈련시킨 SentencePiece를 활용하여 위 함수와 유사한 기능을 하는 sp_tokenize()함수를 정의.\n",
    "\n",
    "하지만 sentencepiece가 동작하는 방식이 단순 토큰화와는 달라 완전히 동일하게 정의하기는 어려움.\n",
    "\n",
    "아래 조건을 만족하는 함수를 정의하도록 하자.\n",
    "\n",
    "    1. 온전한 문장의 list를 전달\n",
    "    2. 생성된 vocab 파일을 읽어와 { <word> : <idx> }형태를 가지는 word_index 사전과 { <idx> : <word> }형태를 가지는 idex_word 사전을 생성하고 함께 반환\n",
    "    3. 리턴값인 tensor는 앞의 함수와 동일하게 토큰화한 후 encoding된 문장이다. 패딩O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6_8V8NXW7hjY"
   },
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "\n",
    "    tensor = []  #변환된 토큰들을 입력할 빈 리스트\n",
    "\n",
    "    for sen in corpus:  #'corpus'리스트에 있는 각 문장('sen')에 대해 반복문을 실행\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "          #spm 모델 s'를 활용해 입력 문장을 토큰화하고, 숫자 시퀀스로 변환한 결과를 'tensor'리스트에 추가\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:  #vocab 파일 열기, 'r': 읽기 모드로 파일 열기\n",
    "        vocab = f.readlines()  #파일을 한 줄씩 읽어와서 리스트로 반환\n",
    "\n",
    "    word_index = {}  #'word_index' 딕셔너리 생성\n",
    "    index_word = {}  #'index_word' 딕셔너리 생성\n",
    "      #생성된 vocab 파일로 각 딕셔너리 형식에 맞게 각각 생성\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "      #'vocab'리스트에 있는 각 줄을 순회하며 인덱스 'idx'와 해달 줄의 내용 'line'을 추출\n",
    "        word = line.split(\"\\t\")[0]\n",
    "          #'line'을 탭('\\t')으로 분리하여 얻은 리스트에서 첫 번째 열에 있는 토큰을 추출하여 'word'변수에 저장\n",
    "          #이렇게 추출된 토큰은 딕셔너리에 토큰과 숫자 ID를 매핑하는데 사용\n",
    "\n",
    "        word_index.update({word:idx})  #토큰을 key로, 해당 토큰의 숫자 id를 value로.\n",
    "          #토큰을 기반으로 숫자ID를 검색.\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "      #변환된 토큰의 숫자 시퀀스를 패딩하여 길이를 맞춤\n",
    "\n",
    "    return tensor, word_index, index_word\n",
    "      #토큰화된 숫자 시퀀스('tensor')와 단어-인덱스 매핑하는 'word_index', 인덱스-단어를 매핑하는 'index_word'를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N86z8cz47mWo"
   },
   "source": [
    "'s.EncoodeAsIds()'는 sentencepiece 모델 's'를 사용하여 주어진 문장을 토큰화하고, 토큰들을 해당하는 숫자ID로 변환하는 메서드.\n",
    "spm은 단어나 서브워드와 같은 토큰들을 숫자 ID로 매핑하는 방식으로 작동.\n",
    "\n",
    "spm을 학습하면, 학습 데이터에서 나타난 서브워드 단위의 패턴이 어휘 사전으로 생성된다.이렇게 생성된 어휘 사전에 따라 문장을 토큰화하고, 토큰들을 해당하는 숫자ID로 변환하는 것이 's.EncodeAsIds()'이다. 즉, 숫자ID 시퀀스로 변환해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF9sot2y7oce"
   },
   "source": [
    "##STEP4. 네이버 영화리뷰 감정 분석 문제에 SentencePiece 적용해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxQTmtHEKnNx"
   },
   "source": [
    "##1.데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "U5KRWQxTJ7vA"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5wgT2GSJ9Q2",
    "outputId": "ccf11e4d-080f-4ca3-f463-3469e5d0ecc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings_test.txt', <http.client.HTTPMessage at 0x7fa5aa08d4c0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2YtlKG4CKJ1d"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_table('ratings_train.txt')\n",
    "test_data = pd.read_table('ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EjPtL9zKLdC",
    "outputId": "c4b1eb1a-f4ae-44ab-8dc1-4fa6b79af63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰 개수 : 150000\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2i3I2AxQKOYt",
    "outputId": "2d058059-e2c8-4afc-a9ae-1596fe2fa856"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5] # 상위 5개 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6lZmCKnKsQS"
   },
   "source": [
    "##2.데이터 전처리 - spm 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHHpOSp0L4m8"
   },
   "source": [
    "**2-1.중복과 null값 제거**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nmVBUd-KuKP",
    "outputId": "ee707da9-9163-4eae-fd84-2dd3558504a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146182, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document 열과 label 열의 중복을 제외한 값의 개수\n",
    "train_data['document'].nunique(), train_data['label'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1CN9KNNbKwcC"
   },
   "outputs": [],
   "source": [
    "# document 열의 중복 제거\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32PYhLyjKyNy",
    "outputId": "037cc4a9-0fc4-4bce-c7e3-523c4e20c510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 146183\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 수 :',len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "dPVusokJK0fO",
    "outputId": "917b0a03-d83e-489b-da00-3a50e3f263b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['label'].value_counts().plot(kind = 'bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9Ztr9jXK3Xr"
   },
   "source": [
    "train data에서 해당 리뷰의 긍정과 부정 유무가 기재되어 있는 label값의 분포가 균일한 것처럼 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5sr4_UtLBjz",
    "outputId": "c86b0624-0b75-4bc0-a91e-413e9d321fe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  count\n",
      "0      0  73342\n",
      "1      1  72841\n"
     ]
    }
   ],
   "source": [
    "print(train_data.groupby('label').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IELjehmQLDqS",
    "outputId": "1ec4f9ed-b28a-4fa9-c3e2-da1397e23ef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#리뷰 중에 Null값을 가진 샘플이 있는지 확인\n",
    "print(train_data.isnull().values.any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8HF5J2DLY7L",
    "outputId": "b86ef3ba-ebcd-4db9-8b54-93c930949f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    1\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Null값이 어떤 열에 존재하는지 확인\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "3qhT7GPVLf9F",
    "outputId": "84d7a84d-d3ea-4589-bce4-175819e0708a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25857</th>\n",
       "      <td>2172111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id document  label\n",
       "25857  2172111      NaN      1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Null값을 가진 샘플의 인덱스 위치 출력\n",
    "train_data.loc[train_data.document.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CfEBdTmLm_y",
    "outputId": "b78c0e3a-5d74-4e76-c057-ac7df0086d93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Null값 가진 샘플을 제거\n",
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhbMOFXbL_H2"
   },
   "source": [
    "**2-2. 텍스트 정규화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "SwLQ_rDOMD2p",
    "outputId": "dc705cc6-5999-4e3a-f6f5-f87f87ec1de2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3868/3525229848.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한글과 공백을 제외하고 모두 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpTnTkZdMc3M",
    "outputId": "8f3a2367-12d8-4561-f6b8-eb01c36f5dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "document    789\n",
      "label         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3868/3514686550.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n"
     ]
    }
   ],
   "source": [
    "#한글이 없는 리뷰는 빈 값이 되었을테니 다시 한번 이상치 제거\n",
    "train_data['document'] = train_data['document'].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n",
    "train_data['document'].replace('', np.nan, inplace=True)\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tcz0Y7hjMoyx",
    "outputId": "c02f1b9b-d313-4aca-b88b-98da770ed9f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4221289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>9509970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>10147571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>7117896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>6478189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id document  label\n",
       "404   4221289      NaN      0\n",
       "412   9509970      NaN      1\n",
       "470  10147571      NaN      1\n",
       "584   7117896      NaN      0\n",
       "593   6478189      NaN      0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Null값 상위 5개 출력\n",
    "train_data.loc[train_data.document.isnull()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-4Z3c2hMrhg",
    "outputId": "683f5501-b113-4518-b9c1-e572f0c4a873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145393\n"
     ]
    }
   ],
   "source": [
    "#Null값 제거\n",
    "train_data = train_data.dropna(how = 'any')\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMfxTmNqM0so",
    "outputId": "2dd3f9dc-1458-4ceb-f904-d26411e17ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 테스트용 샘플의 개수 : 48852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3868/1404236827.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
      "/tmp/ipykernel_3868/1404236827.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n"
     ]
    }
   ],
   "source": [
    "#테스트 데이터도 똑같이 전처리\n",
    "test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
    "test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n",
    "test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
    "test_data = test_data.dropna(how='any') # Null 값 제거\n",
    "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaRrd6XzPjhN"
   },
   "source": [
    "**2-3. spm을 통한 토큰화**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tn-UUlgSRCu9",
    "outputId": "7da0d01a-5ca4-45ba-e23a-af50fa8f257c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1rlPVy5V0O-",
    "outputId": "6406f05d-d2c4-463d-8e3d-5872a0eb7a6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         아 더빙 진짜 짜증나네요 목소리\n",
       "1                                흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나\n",
       "2                                         너무재밓었다그래서보는것을추천한다\n",
       "3                                 교도소 이야기구먼 솔직히 재미는 없다평점 조정\n",
       "4         사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...\n",
       "                                ...                        \n",
       "149995                                      인간이 문제지 소는 뭔죄인가\n",
       "149996                                           평점이 너무 낮아서\n",
       "149997                        이게 뭐요 한국인은 거들먹거리고 필리핀 혼혈은 착하다\n",
       "149998                           청춘 영화의 최고봉방황과 우울했던 날들의 자화상\n",
       "149999                             한국 영화 최초로 수간하는 내용이 담긴 영화\n",
       "Name: document, Length: 145393, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data의 document 열을 sentence에 할당\n",
    "sentence = train_data['document']\n",
    "\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "_rHZd-mrPnBi",
    "outputId": "fdcd19c2-8138-468d-85dd-3807e1ec176e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min length :  1\n",
      "Max length :  140\n",
      "Average length :  33\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for s in sentence:\n",
    "  if len(s) < min_len :\n",
    "    min_len = len(s)\n",
    "  if len(s) > max_len :\n",
    "    max_len = len(s)\n",
    "  sum_len += len(s)\n",
    "\n",
    "print('Min length : ', min_len)\n",
    "print('Max length : ', max_len)\n",
    "print('Average length : ', sum_len // len(sentence))\n",
    "\n",
    "sen_length_cnt = [0] * max_len\n",
    "for sen in sentence:\n",
    "  sen_length_cnt[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sen_length_cnt, width=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSpDUJy6Rq7W",
    "outputId": "8ae10a5e-bc81-4ad4-c9ab-b2caa015d07c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130416\n",
      "130416\n"
     ]
    }
   ],
   "source": [
    "max_len = 150\n",
    "min_len = 10\n",
    "\n",
    "filtered_sen = []  #10 < 문장 길이 < 150에 해당하는 문장들을 저장하는 리스트\n",
    "filtered_target = []  #해당 문장들에 대응하는 레이블을 저장하는 리스트\n",
    "\n",
    "target = np.array(train_data['label'])\n",
    "\n",
    "for s, t in zip(sentence, target):\n",
    "  if (len(str(s)) < max_len) and (len(str(s)) >= min_len) :\n",
    "    filtered_sen.append(s)\n",
    "    filtered_target.append(t)\n",
    "\n",
    "print(len(filtered_sen))\n",
    "print(len(filtered_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ui__RVbkSFyc",
    "outputId": "a7508a75-e59c-4ea3-b305-7f2f47a463f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/naver_MovieReview/ratings_test.txt.temp --model_prefix=ratings_train --vocab_size=130000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/naver_MovieReview/ratings_test.txt.temp\n",
      "  input_format: \n",
      "  model_prefix: ratings_train\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 130000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/naver_MovieReview/ratings_test.txt.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 130416 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=4836626\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1538\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 130416 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 311797 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 130416\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 293735\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 293735 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=151576 obj=14.0077 num_tokens=613805 num_tokens/piece=4.04949\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=139447 obj=13.0972 num_tokens=616844 num_tokens/piece=4.4235\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: ratings_train.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: ratings_train.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root  2951646 Aug 16 08:12 ratings_train.model\r\n",
      "-rw-r--r-- 1 root root 14628807 Aug 16 08:10 ratings_train.txt\r\n",
      "-rw-r--r-- 1 root root  2829626 Aug 16 08:12 ratings_train.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "temp_file_path = os.getenv('HOME')+'/aiffel/sp_tokenizer/naver_MovieReview/ratings_test.txt.temp'\n",
    "\n",
    "vocab_size = 130000\n",
    "\n",
    "with open(temp_file_path, 'w') as f:\n",
    "  for row in filtered_sen:\n",
    "    f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(  #sentencepiece를 사용하여 토크나이저를 훈련\n",
    "    '--input={} --model_prefix=ratings_train --vocab_size={}'.format(temp_file_path, vocab_size)\n",
    ")\n",
    "\n",
    "!ls -l ratings_train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9eG_o6KUII-",
    "outputId": "ebb123f6-a0be-4e9f-b040-b2d4f0ee201c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14778, 18011, 22711, 37515, 0]\n",
      "['▁어머니가', '방에', '들어가', '신', '다', '.']\n",
      "어머니가방에들어가신다 ⁇ \n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('ratings_train.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('어머니가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('어머니가방에들어가신다.',2, 0.1))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "fDUCp04pYiu9"
   },
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./ratings_train.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word\n",
    "\n",
    "tensor, word_index, index_word = sp_tokenize(s, filtered_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "qxldlkO-RejX",
    "outputId": "d0050c70-e0e3-4fea-e719-3236cee6b877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 140\n",
      "문장의 평균 길이: 33\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#문장 길이 확인.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in sentence:  #'sentence'리스트에 있는 각 문장('sen')에 대해 반복문을 실행\n",
    "    length = len(sen)  #현재 문장'sen'의 길이를 구해서 'length'변수에 할당\n",
    "    if min_len > length: min_len = length  #현재 문장의 길이가 ' min_len'변수에 저장된 최소 길이보다 작다면, 'min_len'변수에 현재 길이를 저장.\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length  #현재 문장의 길이를 'sum_len'변수에 더함. 'sum_len'변수는 전체 길이의 합을 나타내며, 문장 길이의 총합을 계산\n",
    "#'sentence'리스트에 잇는 모든 문장을 반복하면서 각 문장의 길이를 계산하고, 최소 길이와 최대 길이를 업데이트하며 전체 길이의 합을 계산.\n",
    "\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(sentence))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)  #길이가 'max_len'이고 0으로 초기화된 Numpy 배열\n",
    "                                                  #sentence_length 배열의 dtype = 정수\n",
    "\n",
    "for sen in sentence:  #'sentence'리스트에 있는 각 문장('sen')에 대해 반복문을 실행\n",
    "    sentence_length[len(sen)-1] += 1  #'len(sen)-1': 현재 문장의 길이에서 1을 뺀 값 = 문장 길이를 배열 인덱스에 맞게 변환\n",
    "                                      #길이가 1인 문장은 배열의 첫 번째 요소에 저장. 길이가 2인 문장은 두 번째 요소에 저장.\n",
    "                                      #계산된 인덱스 위치에 해당하는 'sentence_length'배열의 값을 1 증가. 이를 통해 해당 길이의 문장이 등장한 빈도를 저장.\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_Met_W8ZPdF"
   },
   "source": [
    "##3.모델 구현 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "5_UJfCPKZObQ"
   },
   "outputs": [],
   "source": [
    "# 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(tensor, filtered_target, test_size=0.2)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9qgo6Bcyrud",
    "outputId": "c4aac361-0739-4210-b00e-a2bbc3db8c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         26000000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 26,172,609\n",
      "Trainable params: 26,172,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 설계\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = vocab_size\n",
    "word_vector_dim = 200\n",
    "\n",
    "model_rnn = tf.keras.Sequential()\n",
    "model_rnn.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_rnn.add(tf.keras.layers.LSTM(128))\n",
    "model_rnn.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model_rnn.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "pJfw6gZGy1gb",
    "outputId": "a3aad4bc-ce66-42d6-bbc2-7b7947d53c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "816/816 [==============================] - 18s 21ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.4974\n",
      "Epoch 2/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 3/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 4/20\n",
      "816/816 [==============================] - 17s 20ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 5/20\n",
      "816/816 [==============================] - 17s 20ms/step - loss: 0.6931 - accuracy: 0.5007 - val_loss: 0.6932 - val_accuracy: 0.4974\n",
      "Epoch 6/20\n",
      "816/816 [==============================] - 17s 20ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 7/20\n",
      "816/816 [==============================] - 17s 20ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.4974\n",
      "Epoch 8/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 9/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 10/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6932 - val_accuracy: 0.4974\n",
      "Epoch 11/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 12/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.4974\n",
      "Epoch 13/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6931 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.4974\n",
      "Epoch 14/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6931 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 15/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.4974\n",
      "Epoch 16/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6931 - accuracy: 0.5006 - val_loss: 0.6932 - val_accuracy: 0.4974\n",
      "Epoch 17/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 18/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 19/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 20/20\n",
      "816/816 [==============================] - 17s 21ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.5026\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mc = ModelCheckpoint(\"splstm.h5\", monitor='val_accuracy',save_best_only=True)\n",
    "\n",
    "model_rnn.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history_rnn = model_rnn.fit(x_train,\n",
    "                              y_train,\n",
    "                              epochs=epochs,\n",
    "                              callbacks=[mc],\n",
    "                              batch_size=128,\n",
    "                              validation_data=(x_val, y_val),\n",
    "                              verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VJzMV-u1FGW"
   },
   "source": [
    "##4.평가하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48852\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(s.EncodeAsIds(x) for x in test_data['document'])\n",
    "y_test = np.array(test_data['label'])\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(x_test))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type generator).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3868/3263410499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'splstm.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_rnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1467\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m                **kwargs):\n\u001b[1;32m    229\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    232\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type generator)."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('splstm.h5')\n",
    "results = model_rnn.evaluate(x_test, y_test, verbose=2)\n",
    "print(results_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "TcGzSW5C1cvl"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'int\\'>\"})'}), <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3868/2012128038.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 평가하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_rnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhistory_dict_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1467\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1135\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    974\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    977\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'int\\'>\"})'}), <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "# 평가하기\n",
    "results_rnn = model_rnn.evaluate(x_test, y_test, verbose=2)\n",
    "print(results_rnn)\n",
    "\n",
    "history_dict_rnn = history_rnn.history\n",
    "\n",
    "# train과 val의 Loss\n",
    "acc_rnn = history_dict_rnn['accuracy']\n",
    "val_acc_rnn = history_dict_rnn['val_accuracy']\n",
    "loss_rnn = history_dict_rnn['loss']\n",
    "val_loss_rnn = history_dict_rnn['val_loss']\n",
    "\n",
    "epochs_rnn = range(1, len(acc_rnn) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"\n",
    "plt.plot(epochs_rnn, loss_rnn, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"\n",
    "plt.plot(epochs_rnn, val_loss_rnn, 'b', label='Validation loss')\n",
    "plt.title('RNN\\'s Training & validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# train과 val의 accuracy\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs_rnn, acc_rnn, 'bo', label='Training acc')\n",
    "plt.plot(epochs_rnn, val_acc_rnn, 'b', label='Validation acc')\n",
    "plt.title('RNN\\'s Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZ_VZLoq3c-u"
   },
   "source": [
    "##5.데이터 전처리-mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWssP9wS3hyj",
    "outputId": "5f671924-0948-4a9f-c990-b2262a3454ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-mecab-ko in /opt/conda/lib/python3.9/site-packages (1.3.3)\n",
      "Requirement already satisfied: python-mecab-ko-dic in /opt/conda/lib/python3.9/site-packages (from python-mecab-ko) (2.1.1.post2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-mecab-ko\n",
    "from mecab import MeCab\n",
    "tokenizer_mecab = MeCab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "2mokTBs83yOm"
   },
   "outputs": [],
   "source": [
    "stopwords_list = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "# load data 함수\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def load_data(train_data, test_data, num_words=16000):\n",
    "  len_train = len(train_data)\n",
    "\n",
    "  train_data = train_data.drop_duplicates('document', keep='first')\n",
    "  test_data = test_data.drop_duplicates('document', keep='first')\n",
    "  train_data = train_data.dropna(axis=0)\n",
    "  test_data = test_data.dropna(axis=0)\n",
    "\n",
    "  sentence_list = list(train_data['document'])\n",
    "\n",
    "  token_list = []\n",
    "  for sen in sentence_list:\n",
    "    tokenize_sentence = tokenizer_mecab.morphs(sen)\n",
    "    tokenize_sentence = [word for word in tokenize_sentence if word not in stopwords_list]\n",
    "    token_list.append(tokenize_sentence)\n",
    "\n",
    "  x_train = token_list[:len_train]\n",
    "  x_val = token_list[len_train:]\n",
    "\n",
    "  words = np.concatenate(x_train).tolist()\n",
    "  counter = Counter(words)\n",
    "  counter = counter.most_common(15000-4)\n",
    "  vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "\n",
    "  word2index = {word : index for index, word in enumerate(vocab)}\n",
    "\n",
    "  def wordlist_to_indexlist(wordlist):\n",
    "    return [word2index[word] if word in word2index else word2index['<UNK>'] for word in wordlist]\n",
    "\n",
    "  x_train=np.array(list(map(wordlist_to_indexlist, x_train)), dtype=object)\n",
    "  x_val = np.array(list(map(wordlist_to_indexlist, x_val)), dtype=object)\n",
    "\n",
    "  return x_train, np.array(list(train_data['label'][:len_train]), dtype=object), x_val, np.array(list(train_data['label'][len_train:]), dtype=object), word2index\n",
    "x_train, y_train, x_val, y_val, word2index = load_data(train_data, test_data)\n",
    "\n",
    "index2word = {index : word for word, index in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvICbyXo6Q6i",
    "outputId": "12724f6d-730b-4e70-dc21-aafd7338b927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  13.939966578470965\n",
      "문장길이 최대 :  83\n",
      "문장길이 표준편차 :  11.437878687723702\n",
      "pad_sequences maxlen :  36\n",
      "전체 문장의 0.9327252471800584%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "#토큰화 된 문장들의 길이 분포 확인, 패딩을 위한 최대 문장 길이 지정\n",
    "\n",
    "total_data_text = list(x_train) + list(x_val)\n",
    "\n",
    "# 텍스트데이터 문장길이의 리스트를 생성\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 최대 길이를 (평균 + 2 * 표준편차) 로 한다면 남는 문장의 비율은?\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "FStEoNkb87iJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 문장의 마지막 입력이 최종 state에 영향을 가장 크게 미치기 때문에 패딩 적용은 pre(앞쪽)으로 해줍니다.\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word2index['<PAD>'],\n",
    "                                                        padding = 'pre',\n",
    "                                                        maxlen = maxlen)\n",
    "\n",
    "\n",
    "x_val = tf.keras.preprocessing.sequence.pad_sequences(x_val,\n",
    "                                                       value=word2index[\"<PAD>\"],\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_m7fzGN9F8K"
   },
   "source": [
    "##6.모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "NVOhbXIs9MB6"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "x_val = x_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "R2FXPfuG9bKz"
   },
   "outputs": [],
   "source": [
    "vocab_size = 16000\n",
    "word_vector_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V24z1Hfj9dsF",
    "outputId": "4b8ca7a4-0e3a-4fd7-858b-a8331dc92cf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 200)         3200000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,372,609\n",
      "Trainable params: 3,372,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn_mecab = tf.keras.Sequential()\n",
    "model_rnn_mecab.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_rnn_mecab.add(tf.keras.layers.LSTM(128))\n",
    "model_rnn_mecab.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model_rnn_mecab.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_rnn_mecab.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "MyPkOxMMIpAy",
    "outputId": "a7826288-cb91-4df8-e02c-9d5f4b99c170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2245/2245 [==============================] - 14s 6ms/step - loss: 0.3690 - accuracy: 0.8335\n",
      "Epoch 2/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.2817 - accuracy: 0.8795\n",
      "Epoch 3/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.2310 - accuracy: 0.9045\n",
      "Epoch 4/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.1843 - accuracy: 0.9257\n",
      "Epoch 5/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.1451 - accuracy: 0.9416\n",
      "Epoch 6/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.1150 - accuracy: 0.9537\n",
      "Epoch 7/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0916 - accuracy: 0.9634\n",
      "Epoch 8/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0741 - accuracy: 0.9704\n",
      "Epoch 9/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0600 - accuracy: 0.9761\n",
      "Epoch 10/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0505 - accuracy: 0.9799\n",
      "Epoch 11/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0417 - accuracy: 0.9833\n",
      "Epoch 12/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0351 - accuracy: 0.9860\n",
      "Epoch 13/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0311 - accuracy: 0.9874\n",
      "Epoch 14/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0267 - accuracy: 0.9896\n",
      "Epoch 15/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0238 - accuracy: 0.9904\n",
      "Epoch 16/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0213 - accuracy: 0.9916\n",
      "Epoch 17/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0195 - accuracy: 0.9923\n",
      "Epoch 18/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0174 - accuracy: 0.9930\n",
      "Epoch 19/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0151 - accuracy: 0.9938\n",
      "Epoch 20/20\n",
      "2245/2245 [==============================] - 13s 6ms/step - loss: 0.0151 - accuracy: 0.9938\n"
     ]
    }
   ],
   "source": [
    "model_rnn_mecab.compile(optimizer = 'adam',\n",
    "                         loss = 'binary_crossentropy',\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history_rnn_mecab = model_rnn_mecab.fit(x_train,\n",
    "                                          y_train,\n",
    "                                          epochs=epochs,\n",
    "                                          batch_size=64,\n",
    "                                          validation_data=(x_val, y_val),\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 처리하는 과정에 train_data와 test_data를 합쳐버려서 모델이 과적합돼버렸다. 그래서 다시 대부분의 시간을 다시 분리시키는데 썼다. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
